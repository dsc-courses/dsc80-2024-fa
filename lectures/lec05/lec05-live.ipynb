{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c8a44b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dsc80_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eebbfda-0784-4acf-a0cb-90120b920240",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script type=\"text/javascript\" src=\"https://pandastutor.com/build/wsembed.bundle.2022-07-07-release.js\"></script>\n",
       "<script>\n",
       "console.log(\"initializing pandas_tutor js\")\n",
       "\n",
       "function drawWsv(viz_id, spec, options) {\n",
       "  if (typeof createWsvFromPandasTrace === 'undefined') {\n",
       "    setTimeout(() => drawWsv(viz_id, spec, options), 2000) // retry in 2 seconds\n",
       "    return\n",
       "  }\n",
       "  createWsvFromPandasTrace(viz_id, spec, options)\n",
       "}\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pandas Tutor setup\n",
    "%reload_ext pandas_tutor\n",
    "%set_pandas_tutor_options {\"maxDisplayCols\": 8, \"nohover\": True, \"projectorMode\": True}\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e66d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 5 â€“ Exploratory Data Analysis and Data Cleaning\n",
    "\n",
    "## DSC 80, Fall 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements ðŸ“£\n",
    "\n",
    "- Lab 2 due tomorrow, **Fri, Oct 11**.\n",
    "- Project 1 is due this **Tue, Oct 15**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd851d5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda ðŸ“†\n",
    "\n",
    "- Dataset overview.\n",
    "- Introduction to `plotly`.\n",
    "- Exploratory data analysis and feature types.\n",
    "- Data cleaning.\n",
    "    - Data quality checks.\n",
    "    - Missing values.\n",
    "    - Transformations and timestamps.\n",
    "    - Modifying structure.\n",
    "- Investigating student-submitted questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e6b334-131a-4bd3-a3da-637d702ebf51",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c15f411-2990-4f31-98b6-1fe8e55817cb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Example: Name categories\n",
    "\n",
    "The [New York Times article from Lecture 1](https://archive.is/NpORG) claims that certain categories of names are becoming more popular. For example:\n",
    "\n",
    "- Forbidden names like Lucifer, Lilith, Kali, and Danger.\n",
    "\n",
    "- Evangelical names like Amen, Savior, Canaan, and Creed.\n",
    "\n",
    "- Mythological names.\n",
    "\n",
    "- It also claims that baby boomer names are becoming less popular.\n",
    "\n",
    "Let's see if we can verify these claims using data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4960d5ec-d3b5-4ae2-bb5c-b822334e7cb9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Loading in the data\n",
    "\n",
    "Our first DataFrame, `baby`, is the same as we saw in Lecture 1. It has one row for every combination of `'Name'`, `'Sex'`, and `'Year'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05bad6f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "baby_path = Path('data') / 'baby.csv'\n",
    "baby = pd.read_csv(baby_path)\n",
    "baby"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02253dcc-b6f5-4ada-8e49-bc5096257eb3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Our second DataFrame, `nyt`, contains the New York Times' categorization of each of several names, based on the aforementioned article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60eca7e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nyt_path = Path('data') / 'nyt_names.csv'\n",
    "nyt = pd.read_csv(nyt_path)\n",
    "nyt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81491519-cf2c-486f-9b82-8898bd73549a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Issue**: To find the number of babies born with (for example) forbidden names each year, we need to combine information from both `baby` and `nyt`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e305183-0ee5-4652-8c9d-cbf78acaf459",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Merging\n",
    "\n",
    "- We want to link rows from `baby` and `nyt` together whenever the names match up.\n",
    "- This is a **merge** (`pandas` term), i.e. a **join** (SQL term).\n",
    "- A merge is appropriate when we have two sources of information **about the same individuals** that is **linked by a common column(s)**.\n",
    "- The common column(s) are called the **join key**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a41c8c-7c46-4396-837c-f6170814af17",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Example merge\n",
    "\n",
    "Let's demonstrate on a small subset of `baby` and `nyt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abff9e98",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nyt_small = nyt.iloc[[11, 12, 14]].reset_index(drop=True)\n",
    "\n",
    "names_to_keep = ['Julius', 'Karen', 'Noah']\n",
    "baby_small = (baby\n",
    " .query(\"Year == 2020 and Name in @names_to_keep\")\n",
    " .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "dfs_side_by_side(baby_small, nyt_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21686fc2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%pt\n",
    "baby_small.merge(nyt_small, left_on='Name', right_on='nyt_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09619930-ac5b-43c9-aac5-22210322b1d7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### The `merge` method\n",
    "\n",
    "- The `merge` DataFrame method joins two DataFrames by columns or indexes.\n",
    "    - As mentioned before, \"merge\" is just the `pandas` word for \"join.\"\n",
    "\n",
    "- When using the `merge` method, the DataFrame before `merge` is the \"left\" DataFrame, and the DataFrame passed into `merge` is the \"right\" DataFrame.\n",
    "    - In `baby_small.merge(nyt_small)`, `baby_small` is considered the \"left\" DataFrame and `nyt_small` is the \"right\" DataFrame; the columns from the left DataFrame appear to the left of the columns from right DataFrame.\n",
    "\n",
    "- By default:\n",
    "    - If join keys are not specified, all shared columns between the two DataFrames are used.\n",
    "    - The \"type\" of join performed is an inner join. **This is the only type of join you saw in DSC 10, but there are more, as we'll now see!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbae422-fb53-4cbf-ac74-01c30341d365",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Join types: inner joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2206e6f8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%pt\n",
    "baby_small.merge(nyt_small, left_on='Name', right_on='nyt_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8102e1-5c5e-48ac-9f89-1b63768eb6e3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Note that `'Noah'` and `'Freya'` do not appear in the merged DataFrame.\n",
    "- This is because there is:\n",
    "    - no `'Noah'` in the right DataFrame (`nyt_small`), and\n",
    "    - no `'Freya'` in the left DataFrame (`baby_small`).\n",
    "- The default type of join that `merge` performs is an **inner join**, which keeps the **intersection** of the join keys.\n",
    "\n",
    "\n",
    "<center><img src='imgs/image_0.png' width=20%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e488388-db87-4899-b0c1-5c9507fdeaee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Different join types\n",
    "\n",
    "We can change the type of join performed by changing the `how` argument in `merge`. Let's experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc6919",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%pt\n",
    "# Note the NaNs!\n",
    "baby_small.merge(nyt_small, left_on='Name', right_on='nyt_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f81ba5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%pt\n",
    "baby_small.merge(nyt_small, left_on='Name', right_on='nyt_name', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e30fa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%pt\n",
    "baby_small.merge(nyt_small, left_on='Name', right_on='nyt_name', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2956b278-d404-4fc8-bb04-c0d026825860",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Different join types handle mismatches differently\n",
    "\n",
    "There are four types of joins.\n",
    "\n",
    "* **Inner**: keep **only** matching keys (intersection).\n",
    "* **Outer**: keep **all** keys in both DataFrames (union).\n",
    "* **Left**: keep all keys in the left DataFrame, whether or not they are in the right DataFrame.\n",
    "* **Right**: keep all keys in the right DataFrame, whether or not they are in the left DataFrame.\n",
    "    * Note that `a.merge(b, how='left')` contains the same information as `b.merge(a, how='right')`, just in a different order.\n",
    "\n",
    "<center><img src='imgs/image_1.png' width=30%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3162c948-1ba7-434d-b5dd-6c38fe210a40",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Notes on the `merge` method\n",
    "\n",
    "- `merge` is flexible â€“ you can merge using a combination of columns, or the index of the DataFrame.\n",
    "-  If the two DataFrames have the same column names, `pandas` will add `_x` and `_y` to the duplicated column names to avoid having columns with the same name (change these the `suffixes` argument).\n",
    "- There is, in fact, a `join` method, but it's actually a wrapper around `merge` with fewer options.\n",
    "- **As always, the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) is your friend!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e064ab2-ff79-47d0-9568-877081b9ec11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Lots of `pandas` operations do an implicit outer join!\n",
    "\n",
    "- `pandas` will almost always try to match up index values using an outer join.\n",
    "- It won't tell you that it's doing an outer join, it'll just throw `NaN`s in your result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c823f754",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'a': [1, 2, 3]}, index=['hello', 'dsc80', 'students'])\n",
    "df2 = pd.DataFrame({'b': [10, 20, 30]}, index=['dsc80', 'is', 'awesome'])\n",
    "dfs_side_by_side(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8c3c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1['a'] + df2['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e30f50-3f62-4e90-ae51-fe351884f208",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Many-to-one & many-to-many joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e93bdc-c79c-4ea3-9210-ad993593d486",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### One-to-one joins\n",
    "\n",
    "- So far in this lecture, the joins we have worked with are called **one-to-one** joins.\n",
    "- Neither the left DataFrame (`baby_small`) nor the right DataFrame (`nyt_small`) contained any duplicates in the join key.\n",
    "- What if there are duplicated join keys, in one or both of the DataFrames we are merging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5378a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up the next example.\n",
    "profs = pd.DataFrame(\n",
    "[['Sam', 'UCB', 5],\n",
    " ['Sam', 'UCSD', 5],\n",
    " ['Janine', 'UCSD', 8],\n",
    " ['Marina', 'UIC', 7],\n",
    " ['Justin', 'OSU', 5],\n",
    " ['Soohyun', 'UCSD', 2],\n",
    " ['Suraj', 'UCB', 2]],\n",
    "    columns=['Name', 'School', 'Years']\n",
    ")\n",
    "\n",
    "schools = pd.DataFrame({\n",
    "    'Abr': ['UCSD', 'UCLA', 'UCB', 'UIC'],\n",
    "    'Full': ['University of California San Diego', 'University of California, Los Angeles', 'University of California, Berkeley', 'University of Illinois Chicago']\n",
    "})\n",
    "\n",
    "programs = pd.DataFrame({\n",
    "    'uni': ['UCSD', 'UCSD', 'UCSD', 'UCB', 'OSU', 'OSU'],\n",
    "    'dept': ['Math', 'HDSI', 'COGS', 'CS', 'Math', 'CS'],\n",
    "    'grad_students': [205, 54, 281, 439, 304, 193]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5412c15-7734-402b-8b41-dfd41655f219",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Many-to-one joins\n",
    "\n",
    "- Many-to-one joins are joins where **one** of the DataFrames contains duplicate values in the join key. \n",
    "- The resulting DataFrame will preserve those duplicate entries as appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7d4ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs_side_by_side(profs, schools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1314f5d3-269e-4554-a3f8-3e928748c539",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Note that when merging `profs` and `schools`, the information from `schools` is duplicated.\n",
    "- `'University of California, San Diego'` appears three times.\n",
    "- `'University of California, Berkeley'` appears twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a18661",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%pt\n",
    "profs.merge(schools, left_on='School', right_on='Abr', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaac39e-b3c9-4aeb-a876-502548543400",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Many-to-many joins\n",
    "\n",
    "Many-to-many joins are joins where both DataFrames have duplicate values in the join key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3942476b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs_side_by_side(profs, programs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bca337e-03f3-4775-9ea9-2f811e8cf7bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Before running the following cell, try predicting the number of rows in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4fb512",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%pt\n",
    "profs.merge(programs, left_on='School', right_on='uni')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0396291-22b2-4722-b345-88dc35b2d2ad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- `merge` stitched together every UCSD row in `profs` with every UCSD row in `programs`. \n",
    "- Since there were 3 UCSD rows in `profs` and 3 in `programs`, there are $3 \\cdot 3 = 9$ UCSD rows in the output. The same applies for all other schools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d089d9-e14e-4071-a838-8265b2392042",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ðŸ¤” (Answer at <a href=\"https://dsc80.com/q\">dsc80.com/q</a>)</h3>\n",
    "\n",
    "Code: `merge`\n",
    "</div>\n",
    "    \n",
    "Fill in the blank so that the last statement evaluates to `True`.\n",
    "\n",
    "```python\n",
    "df = profs.merge(programs, left_on='School', right_on='uni')\n",
    "df.shape[0] == (____).sum()\n",
    "```\n",
    "\n",
    "**Don't** use `merge` (or `join`) in your solution!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c1851",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs_side_by_side(profs, programs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f90816",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4f507d-3c14-4fc7-bed3-acdb0d339c67",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Returning back to our original question\n",
    "\n",
    "Let's find the popularity of baby name categories over time. To start, we'll define a DataFrame that has one row for every combination of `'category'` and `'Year'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df991fd7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cate_counts = (\n",
    "    baby\n",
    "    .merge(nyt, left_on='Name', right_on='nyt_name')\n",
    "    .groupby(['category', 'Year'])\n",
    "    ['Count']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "cate_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03159ce1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We'll talk about plotting code soon!\n",
    "import plotly.express as px\n",
    "fig = px.line(cate_counts, x='Year', y='Count',\n",
    "              facet_col='category', facet_col_wrap=3,\n",
    "              facet_row_spacing=0.15,\n",
    "              width=600, height=400)\n",
    "fig.update_yaxes(matches=None, showticklabels=False)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd66502-c203-452d-8214-d6f5d5ecc5c8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>Questions? ðŸ¤”</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73600922-be8b-436e-86e3-5f7ce31c83d3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a2f58-0405-495e-b4d8-3477797436c3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Transforming values\n",
    "\n",
    "- A **transformation** results from performing some operation on every element in a sequence, e.g. a Series.\n",
    "\n",
    "- While we haven't discussed it yet in DSC 80, you learned how to transform Series in DSC 10, using the `apply` method. `apply` is very flexible â€“ it takes in a function, which itself takes in a single value as input and returns a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c368e07",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963201ff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def number_of_vowels(string):\n",
    "    return sum(c in 'aeiou' for c in string.lower())\n",
    "\n",
    "baby['Name'].apply(number_of_vowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a89fed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Built-in functions work with apply, too.\n",
    "baby['Name'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297c0274-1bbb-49e2-acff-ab8b28ae17b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### The price of `apply`\n",
    "\n",
    "Unfortunately, `apply` runs really slowly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995da2be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "baby['Name'].apply(number_of_vowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f698c9b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "res = []\n",
    "for name in baby['Name']:\n",
    "    res.append(number_of_vowels(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2583ec8d-d5cf-40b9-9d56-396aa74b0d27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Internally, `apply` actually just runs a `for`-loop!**\n",
    "\n",
    "**So, when possible â€“ say, when applying arithmetic operations â€“ we should work on Series objects directly and avoid `apply`!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc2c205-54a7-4f31-b8ce-65a32700212c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### The price of `apply`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ec65ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "baby['Year'] // 10 * 10 # Rounds down to the nearest multiple of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c3a09",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "baby['Year'].apply(lambda y: y // 10 * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5731fd-15b1-4442-b3d5-8dc41be7b69d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**100x slower!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb06e77-68b8-4e6d-9faa-8f7e70148846",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### The `.str` accessor\n",
    "\n",
    "For string operations, `pandas` provides a convenient `.str` accessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5ee7d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "baby['Name'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b803b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "baby['Name'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e0a445-38e0-4f0c-a306-b4a83d283535",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "It's very convenient and **runs about the same speed as `apply`!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ed6c3a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f5d3b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### San Diego food safety\n",
    "\n",
    "From [this article](https://inewsource.org/2023/02/09/san-diego-restaurants-food-safety-violations/) ([archive link](https://archive.ph/gz8BL)):\n",
    "\n",
    "> In the last three years, one third of San Diego County restaurants have had at least one major food safety violation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353a6782",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 99% Of San Diego Restaurants Earn â€˜A' Grades, Bringing Usefulness of System Into Question\n",
    "\n",
    "From [this article](https://www.nbcsandiego.com/news/local/99-of-san-diego-restaurants-earn-a-grades-bringing-usefulness-of-system-into-question/25381/) ([archive link](https://archive.ph/yB6RU)):\n",
    "\n",
    "> Food held at unsafe temperatures. Employees not washing their hands. Dirty countertops. Vermin in the kitchen. An expired restaurant permit.\n",
    "> \n",
    "> Restaurant inspectors for San Diego County found these violations during a routine health inspection of a diner in La Mesa in November 2016. Despite the violations, the restaurant was awarded a score of 90 out of 100, the lowest possible score to achieve an â€˜Aâ€™ grade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac10042",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The data\n",
    "\n",
    "- We downloaded the data about the 1000 restaurants closest to UCSD from [here](https://www.sandiegocounty.gov/content/sdc/deh/fhd/ffis/intro.html.html).\n",
    "- We had to download the data as JSON files, then process it into DataFrames. You'll learn how to do this soon!\n",
    "    - Until now, you've (largely) been presented with CSV files that `pd.read_csv` could load without any issues.\n",
    "    - But there are many different formats and possible issues when loading data in from files.\n",
    "    - See [Chapter 8 of Learning DS](https://learningds.org/ch/08/files_intro.html) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_path = Path('data') / 'restaurants.csv'\n",
    "insp_path = Path('data') / 'inspections.csv'\n",
    "viol_path = Path('data') / 'violations.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4497b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest = pd.read_csv(rest_path)\n",
    "insp = pd.read_csv(insp_path)\n",
    "viol = pd.read_csv(viol_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e5db5f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ðŸ¤” (Answer at <a href=\"https://dsc80.com/q\">dsc80.com/q</a>)</h3>\n",
    "\n",
    "Code: `dfs`\n",
    "</div>\n",
    "    \n",
    "The first article said that one third of restaurants had at least one major safety violation.<br>\n",
    "Which DataFrames and columns seem most useful to verify this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8367ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0422fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5005c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb951ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf62cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "viol.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b64207",
   "metadata": {},
   "outputs": [],
   "source": [
    "viol.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8cbd01",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introduction to `plotly`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f270da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `plotly`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba464496",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We've used `plotly` in lecture briefly, and you even have to use it in Project 1 Question 13, but we haven't yet discussed it formally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9d895a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It's a visualization library that enables **interactive** visualizations.\n",
    "\n",
    "<center><img src=\"imgs/plotly.png\" width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3d9f3d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using `plotly`\n",
    "\n",
    "There are a few ways we can use `plotly`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622401c8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Using the `plotly.express` syntax.\n",
    "    - `plotly` is very flexible, but it can be verbose; `plotly.express` allows us to make plots quickly.\n",
    "    - See the [**documentation here**](https://plotly.com/python/plotly-express) â€“ it's very rich (there are good examples for almost everything)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d84013",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- By setting `pandas` plotting backend to `'plotly'` (by default, it's `'matplotlib'`) and using the DataFrame `plot` method.\n",
    "    - The DataFrame `plot` method is how you created plots in DSC 10!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd73d31",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For now, we'll use `plotly.express` syntax; we've imported it in the `dsc80_utils.py` file that we import at the top of each lecture notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a04b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Initial plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85364a84",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, let's look at the distribution of inspection `'score'`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74310df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(insp['score'])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de6973",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How about the distribution of average inspection `'score'` per `'grade'`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace9f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = (\n",
    "    insp[['grade', 'score']]\n",
    "    .dropna()\n",
    "    .groupby('grade')\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "# x= and y= are columns of scores. Convenient!\n",
    "px.bar(scores, x='grade', y='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b951fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as the above!\n",
    "scores.plot(kind='bar', x='grade', y='score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16546d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exploratory data analysis and feature types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50511216",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The data science lifecycle, revisited\n",
    "\n",
    "<center>\n",
    "    <img src=\"imgs/ds-lifecycle.svg\" width=50%>\n",
    "</center>\n",
    "\n",
    "We're at the stage of **understanding the data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4dcfca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exploratory data analysis (EDA)\n",
    "\n",
    "- Historically, data analysis was dominated by formal statistics, including tools like confidence intervals, hypothesis tests, and statistical modeling.\n",
    "\n",
    "- In 1977, John Tukey [defined](https://search.worldcat.org/title/3058187) the term **exploratory data analysis**, which described a philosophy for proceeding about data analysis:\n",
    "\n",
    "> Exploratory data analysis is actively incisive, rather than passively descriptive, with real emphasis on the discovery of the unexpected.\n",
    "\n",
    "- Practically, EDA involves, among other things, computing summary statistics and drawing plots to understand the nature of the data at hand.\n",
    "\n",
    "> The greatest gains from data come from surprisesâ€¦ The unexpected is best brought to our attention by **pictures**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b41ad00",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Different feature types\n",
    "\n",
    "<center><img src='imgs/data-types.png' width=90%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7696f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ðŸ¤” (Answer at <a href=\"https://dsc80.com/q\">dsc80.com/q</a>)</h3>\n",
    "\n",
    "Code: `types`\n",
    "</div>\n",
    "    \n",
    "Determine the **feature type** of each of the following variables.\n",
    "    \n",
    "- `insp['score']`\n",
    "- `insp['grade']`\n",
    "- `viol['violation_accela']`\n",
    "- `viol['major_violation']`\n",
    "- `rest['business_id']`\n",
    "- `rest['opened_date']`\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252004ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32888d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature types vs. data types\n",
    "\n",
    "- The data type `pandas` uses is not the same as the \"data type\" we talked about just now!\n",
    "    - There's a difference between feature type and computational data type.\n",
    "\n",
    "- Take care when the two don't match up very well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dab3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas stores these as ints, but they're actually nominal.\n",
    "rest['business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7586f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas stores these as strings, but they're actually numeric.\n",
    "rest['opened_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fdcc40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e1505",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Four pillars of data cleaning\n",
    "\n",
    "When loading in a dataset, to clean the data â€“ that is, to prepare it for further analysis â€“ we will:\n",
    "\n",
    "1. Perform **data quality checks**.\n",
    "\n",
    "2. Identify and handle **missing values**.\n",
    "\n",
    "3. Perform **transformations**, including converting time series data to **timestamps**.\n",
    "\n",
    "4. Modify **structure** as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8786b0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data cleaning: Data quality checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92564b1e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data quality checks\n",
    "\n",
    "We often start an analysis by checking the quality of the data.\n",
    "\n",
    "- Scope: Do the data match your understanding of the population? \n",
    "- Measurements and values: Are the values reasonable?\n",
    "- Relationships: Are related features in agreement?\n",
    "- Analysis: Which features might be useful in a future analysis? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdeb3ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scope\n",
    "\n",
    "Do the data match your understanding of the population?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ecab4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We were told that we're only looking at the 1000 restaurants closest to UCSD, so the restaurants in `rest` should agree with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef21b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1df0230",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Measurements and values\n",
    "\n",
    "Are the values reasonable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c5d81",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Do the values in the `'grade'` column match what we'd expect grades to look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce83dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp['grade'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72806b8d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What kinds of information does the `insp` DataFrame hold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3206cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f33640",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What's going on in the `'address'` column of `rest`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab9641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there multiple restaurants with the same address?\n",
    "rest['address'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d8823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeps all rows with duplicate addresses.\n",
    "(\n",
    "    rest\n",
    "    .groupby('address')\n",
    "    .filter(lambda df: df.shape[0] >= 2)\n",
    "    .sort_values('address')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ace0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the same thing as above!\n",
    "(\n",
    "    rest[rest.duplicated(subset=['address'], keep=False)]\n",
    "    .sort_values('address')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773936b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Relationships\n",
    "\n",
    "Are related features in agreement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4836c4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Do the `'address'`es and `'zip'` codes in `rest` match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4895b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest[['address', 'zip']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e8838b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What about the `'score'`s and `'grade'`s in `insp`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp[['score', 'grade']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7a3c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Analysis\n",
    "\n",
    "Which features might be useful in a future analysis?\n",
    "\n",
    "- We're most interested in:\n",
    "    - These columns in the `rest` DataFrame: `'business_id'`, `'name'`, `'address'`, `'zip'`, and `'opened_date'`.\n",
    "    - These columns in the `insp` DataFrame: `'business_id'`, `'inspection_id'`, `'score'`, `'grade'`, `'completed_date'`, and `'status'`.\n",
    "    - These columns in the `viol` DataFrame: `'inspection_id'`, `'violation'`, `'major_violation'`, `'violation_text'`, and `'violation_accela'`.\n",
    "\n",
    "- Also, let's rename a few columns to make them easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26694343",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ðŸ’¡ Pro-Tip: Using `pipe`\n",
    "\n",
    "When we manipulate DataFrames, it's best to define individual functions for each step, then use the `pipe` **method** to chain them all together.\n",
    "\n",
    "The `pipe` DataFrame method takes in a function, which itself takes in a DataFrame and returns a DataFrame.\n",
    "\n",
    "- In practice, we would add functions one by one to the top of a notebook, then `pipe` them all.\n",
    "- For today, will keep re-running `pipe` to show data cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cbc16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_rest(rest):\n",
    "    return rest[['business_id', 'name', 'address', 'zip', 'opened_date']]\n",
    "\n",
    "rest = (\n",
    "    pd.read_csv(rest_path)\n",
    "    .pipe(subset_rest)\n",
    ")\n",
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2580209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as the above â€“ but the above makes it easier to chain more .pipe calls afterwards.\n",
    "subset_rest(pd.read_csv(rest_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e751e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's use `pipe` to keep (and rename) the subset of the columns we care about in the other two DataFrames as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_insp(insp):\n",
    "    return (\n",
    "        insp[['business_id', 'inspection_id', 'score', 'grade', 'completed_date', 'status']]\n",
    "        .rename(columns={'completed_date': 'date'})\n",
    "    )\n",
    "\n",
    "insp = (\n",
    "    pd.read_csv(insp_path)\n",
    "    .pipe(subset_insp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be8c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_viol(viol):\n",
    "    return (\n",
    "        viol[['inspection_id', 'violation', 'major_violation', 'violation_accela']]\n",
    "        .rename(columns={'violation': 'kind',\n",
    "                         'major_violation': 'is_major',\n",
    "                         'violation_accela': 'violation'})\n",
    "    )\n",
    "\n",
    "viol = (\n",
    "    pd.read_csv(viol_path)\n",
    "    .pipe(subset_viol)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1fd7f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Combining the restaurant data\n",
    "\n",
    "Let's join all three DataFrames together so that we have all the data in a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ca1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_restaurant_data():\n",
    "    return (\n",
    "        rest\n",
    "        .merge(insp, on='business_id', how='left')\n",
    "        .merge(viol, on='inspection_id', how='left')\n",
    "    )\n",
    "\n",
    "df = merge_all_restaurant_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4107683b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ðŸ¤” (Answer at <a href=\"https://dsc80.com/q\">dsc80.com/q</a>)</h3>\n",
    "\n",
    "Code: `lefts`\n",
    "</div>\n",
    "    \n",
    "Why should the function above use two left joins? What would go wrong if we used other kinds of joins?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b92823e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data cleaning: Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7007e6ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Missing values\n",
    "\n",
    "Next, it's important to check for and handle missing values, as they can have a big effect on your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8190fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp[['score', 'grade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proportion of values in each column that are missing.\n",
    "insp.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdee4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Why are there null values here?\n",
    "# insp['inspection_id'] and viol['inspection_id'] don't have any null values...\n",
    "df[df['inspection_id'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afddb353",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are many ways of handling missing values, which we'll cover in an entire lecture next week. But a good first step is to check how many there are!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f39cbc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data cleaning: Transformations and timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce00205",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformations and timestamps\n",
    "\n",
    "From last class:\n",
    "\n",
    "> A transformation results from performing some operation on every element in a sequence, e.g. a Series.\n",
    "\n",
    "It's often useful to look at ways of transforming your data to make it easier to work with.\n",
    "\n",
    "- Type conversions (e.g. changing the string `\"$2.99\"` to the number `2.99`).\n",
    "\n",
    "- Unit conversion (e.g. feet to meters).\n",
    "\n",
    "- Extraction (Getting `'vermin'` out of `'Vermin Violation Recorded on 10/10/2023'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d87244b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating timestamps\n",
    "\n",
    "Most commonly, we'll parse dates into `pd.Timestamp` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e2e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the dtype!\n",
    "insp['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adaa896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This magical string tells Python what format the date is in.\n",
    "# For more info: https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "date_format = '%Y-%m-%d'\n",
    "pd.to_datetime(insp['date'], format=date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54dee4d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Another advantage of defining functions is that we can reuse this function\n",
    "# for the 'opened_date' column in `rest` if we wanted to.\n",
    "def parse_dates(insp, col):\n",
    "    date_format = '%Y-%m-%d'\n",
    "    dates = pd.to_datetime(insp[col], format=date_format)\n",
    "    return insp.assign(**{col: dates})\n",
    "\n",
    "insp = (\n",
    "    pd.read_csv(insp_path)\n",
    "    .pipe(subset_insp)\n",
    "    .pipe(parse_dates, 'date')\n",
    ")\n",
    "\n",
    "# We should also remake df, since it depends on insp.\n",
    "# Note that the new insp is used to create df!\n",
    "df = merge_all_restaurant_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f62bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the dtype now!\n",
    "df['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb9739b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Working with timestamps\n",
    "\n",
    "- We often want to adjust granularity of timestamps to see overall trends, or seasonality.\n",
    "- Use the `resample` method in `pandas` ([documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects)).\n",
    "    - Think of it like a version of `groupby`, but for timestamps.\n",
    "    - For instance, `insp.resample('2W', on='date')` separates every two weeks of data into a different group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa4cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.resample('2W', on='date')['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1823b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where are those numbers coming from?\n",
    "insp[\n",
    "    (insp['date'] >= pd.Timestamp('2020-01-05')) &\n",
    "    (insp['date'] < pd.Timestamp('2020-01-19'))\n",
    "]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d55148",
   "metadata": {},
   "outputs": [],
   "source": [
    "(insp.resample('2W', on='date')\n",
    " .size()\n",
    " .plot(title='Number of Inspections Over Time')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622796b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `.dt` accessor\n",
    "\n",
    "Like with Series of strings, `pandas` has a `.dt` accessor for properties of timestamps ([documentation](https://pandas.pydata.org/docs/user_guide/basics.html#basics-dt-accessors))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3cf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14818dc0",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "insp['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71848903",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "insp['date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ae178",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "dow_counts = insp['date'].dt.dayofweek.value_counts()\n",
    "fig = px.bar(dow_counts)\n",
    "fig.update_xaxes(tickvals=np.arange(7), ticktext=['Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9206c9b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data cleaning: Modifying structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ddb97",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reshaping DataFrames\n",
    "\n",
    "We often **reshape** the DataFrame's structure to make it more convenient for analysis. For example, we can:\n",
    "\n",
    "- Simplify structure by removing columns or taking a set of rows for a particular period of time or geographic area.\n",
    "    - We already did this!\n",
    "\n",
    "- Adjust granularity by aggregating rows together.\n",
    "    - To do this, use `groupby` (or `resample`, if working with timestamps).\n",
    "\n",
    "- Reshape structure, most commonly by using the DataFrame `melt` method to un-pivot a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e99cf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using `melt`\n",
    "\n",
    "- The `melt` method is common enough that we'll give it a special mention.\n",
    "- We'll often encounter pivot tables (esp. from government data), which we call *wide* data.\n",
    "- The methods we've introduced work better with *long-form* data, or *tidy* data.\n",
    "- To go from wide to long, `melt`.\n",
    "\n",
    "<center><img src='imgs/wide-vs-long.svg' width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e43c42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example usage of `melt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54edf07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_example = pd.DataFrame({\n",
    "    'Year': [2001, 2002],\n",
    "    'Jan': [10, 130],\n",
    "    'Feb': [20, 200],\n",
    "    'Mar': [30, 340]\n",
    "}).set_index('Year')\n",
    "wide_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc75510",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_example.melt(ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b77837e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67478028",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ðŸ¤” (Answer at <a href=\"https://dsc80.com/q\">dsc80.com/q</a>)</h3>\n",
    "\n",
    "Code: `qs`\n",
    "</div>\n",
    "    \n",
    "What questions do you want me to try and answer with the data? I'll start with a single pre-prepared question, and then answer student questions until we run out of time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b53b97",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example question: Can we rank restaurants by their number of violations? How about separately for each zip code?\n",
    "\n",
    "And why would we want to do that? ðŸ¤”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df988966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "170d5d0c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dd620d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- Data cleaning is a necessary starting step in data analysis. There are four pillars of data cleaning:\n",
    "    - Quality checks.\n",
    "    - Missing values.\n",
    "    - Transformations and timestamps.\n",
    "    - Modifying structure.\n",
    "- Approach EDA with an open mind, and draw lots of visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8419fc7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "Hypothesis and permutation testing. Some of this will be DSC 10 review, but we'll also push further! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
